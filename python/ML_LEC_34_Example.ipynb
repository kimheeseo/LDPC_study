{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_LEC_34_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwfrLkj6BG/H7i1JvaQJ6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimheeseo/LDPC_study/blob/main/ML_LEC_34_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2azdn9kGiZVt",
        "outputId": "c6604b34-bfd2-4a88-969c-55dc09189cc3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.15.0\n",
            "Uninstalling tensorflow-1.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-1.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15 # 1.15 버전 Tensorflow 설치"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "AHXryjG6ipOJ",
        "outputId": "98c3c4fd-7717-4a94-8ac4-da99d1314a39"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15\n",
            "  Using cached tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.14.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Installing collected packages: tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorflow-1.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "tensorflow_core"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BBOQE7LBjH04",
        "outputId": "f078759f-6f3a-4897-9d78-267df3a5cdb4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL6v2sRFiOmC",
        "outputId": "9d10bec4-6963-4580-8613-a22890ab20dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            " 55000 10000 5000\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
        "\n",
        "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
        "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
        "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
        "\n",
        "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
        "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
        "print(\"train image shape = \", np.shape(mnist.train.images))\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk3Q2agsiWuc",
        "outputId": "c5e4a0a4-b13a-4aaf-acc1-b443cb1cee6a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-Parameter\n",
        "learning_rate = 0.001  # 학습율\n",
        "epochs = 30            # 반복횟수\n",
        "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수"
      ],
      "metadata": {
        "id": "ihh3C5mhiv1q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력과 정답을 위한 플레이스홀더 정의\n",
        "X = tf.placeholder(tf.float32, [None, 784])  \n",
        "\n",
        "T = tf.placeholder(tf.float32, [None, 10])  "
      ],
      "metadata": {
        "id": "OxN18KKLiy2P"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M93Ji_50lQWN",
        "outputId": "f6d36d5a-9603-4432-e67c-44754ae7bd10"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Placeholder_4:0' shape=(?, 784) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번째 컨볼루션층"
      ],
      "metadata": {
        "id": "7eKoKQxui2in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력층의 출력 값. 컨볼루션 연산을 위해 reshape 시킴\n",
        "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28 X 28 X 1 (black/white)\n",
        "# 1번째 컨볼루션 층\n",
        "# 3X3 크기를 가지는 32개의 필터를 적용\n",
        "\n",
        "F2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))  \n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
        "\n",
        "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
        "#입력값이 28*28*1이 되는 데, filter의 갯수가 32개이기에, 28*28*32가 됩니다.\n",
        "C2 = tf.nn.conv2d(A1, F2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "#padding='SAME'에 의해서, 32이 유지되고, stride값이 1이기에, 28*28이 됩니다.\n",
        "#따라서 아래와 같이 C2의 shape은 28*28*32가 됩니다.\n",
        "\n",
        "# relu\n",
        "Z2 = tf.nn.relu(C2+b2)\n",
        "\n",
        "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
        "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "#A2 전까지인 Z2의 경우, 28*28*32였는데, 여기에서 stride값이 2이기 때문에 1/2이 되어서, 14*14*32가 됩니다."
      ],
      "metadata": {
        "id": "95M_AG7YizcW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0hi-23hlbL9",
        "outputId": "98aa4287-59b9-4f9a-cbf1-e8db25d7f39b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Conv2D_3:0' shape=(?, 28, 28, 32) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziBA4r6Jl4W4",
        "outputId": "99a84cf9-c787-46a9-e650-061861cd184e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Relu_3:0' shape=(?, 28, 28, 32) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a9mUrssl54X",
        "outputId": "1a0a8f80-c0b2-4d93-e182-0977441a6321"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool_3:0' shape=(?, 14, 14, 32) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번째 컨볼루션 층"
      ],
      "metadata": {
        "id": "avIm7l1Si5dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번째 컨볼루션 층\n",
        "F3 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))  \n",
        "b3 = tf.Variable(tf.constant(0.1, shape=[64]))   \n",
        "\n",
        "# 2번째 컨볼루션 연산을 통해 14 X 14 X 32 => 14 X 14 X 64 \n",
        "C3 = tf.nn.conv2d(A2, F3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z3 = tf.nn.relu(C3+b3)\n",
        "\n",
        "# 2번째 max pooling을 통해 14 X 14 X 64 => 7 X 7 X 64\n",
        "A3 = P3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "metadata": {
        "id": "RRx-2I_OiRZg"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F3\n",
        "#3*3*32*64는 3*3 크기의 filter를 의미하고, 64는 filter의 갯수를 의미하고, 32는 입력채널\n",
        "#입력 채널 : 데이터가 들어오는 통로"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hlxylJfnE_n",
        "outputId": "79a0efee-25f3-488d-cf6c-2247cf3a0545"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable_14:0' shape=(3, 3, 32, 64) dtype=float32_ref>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C3\n",
        "#14*14*32 -> 14*14*64인데, 우선 padding='SAME'에 의해서, 14*14가 되고,\n",
        "#filter의 갯수가 64이기에, 64가 되어서, 14*14*64가 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R53A_7bn4YO",
        "outputId": "10bdc21f-e93f-4b3f-97f9-949763014dec"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Conv2D_4:0' shape=(?, 14, 14, 64) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpKfbaPRoWun",
        "outputId": "bef449eb-fea4-4c7e-e443-15b58c1c2d14"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Relu_4:0' shape=(?, 14, 14, 64) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A3\n",
        "#원래는 14*14*64 -> 7*7*64인데, 여기서 stride가 2이기 때문에, 14->7로 1/2이 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y6w7Phen4wV",
        "outputId": "c14a4884-5683-4107-c675-db4476a0af76"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool_4:0' shape=(?, 7, 7, 64) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번째 컨볼루션층"
      ],
      "metadata": {
        "id": "OkOo3lifjEVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번째 컨볼루션 층\n",
        "F4 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))  \n",
        "b4 = tf.Variable(tf.constant(0.1, shape=[128]))   \n",
        "\n",
        "# 3번째 컨볼루션 연산을 통해 7 X 7 X 64 => 7 X 7 X 128\n",
        "C4 = tf.nn.conv2d(A3, F4, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "# relu\n",
        "Z4 = tf.nn.relu(C4+b4)\n",
        "\n",
        "# 3번째 max pooling을 통해 7 X 7 X 128 => 4 X 4 X 128\n",
        "A4 = P4 = tf.nn.max_pool(Z4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "metadata": {
        "id": "DUF0KVCVi-lV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F4\n",
        "#(3,3,64,128)이 filter인데, 3*3이 필터의 크기를 나타내고,\n",
        "#128은 필터의 갯수를 나타내고, 64는 입력채널의 수를 나타냅니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmMJVM60otfD",
        "outputId": "6eac45f9-6bc3-4683-c541-13c694c733c7"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable_16:0' shape=(3, 3, 64, 128) dtype=float32_ref>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C4\n",
        "#7*7*64 -> 7*7*128 여기에서 padding='SAME'에 의해서 7*7이 되고,\n",
        "#64->128이 되는 이유는 F4에서 filter의 갯수를 통해, '128'이 된다는 것을 알 수 있습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iSVySC9otny",
        "outputId": "6da3a6bc-d7af-489a-8672-d3ca19107d68"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Conv2D_5:0' shape=(?, 7, 7, 128) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A4\n",
        "#7*7*128 -> 4*4*128이 되는 이유는 stride=2에 의해서 7/2=4로 (4,4,128)이 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JLUUl5lottt",
        "outputId": "6489b0ef-4fbe-4492-92fe-c51242d5ab76"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool_5:0' shape=(?, 4, 4, 128) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4X4 크기를 가진 128개의 activation map을 flatten 시킴\n",
        "A4_flat = P4_flat = tf.reshape(A4, [-1, 128*4*4])\n",
        "# 출력층\n",
        "W5 = tf.Variable(tf.random_normal([128*4*4, 10], stddev=0.01))\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "# 출력층 선형회귀  값 Z5, 즉 softmax 에 들어가는 입력 값\n",
        "Z5 = logits = tf.matmul(A4_flat, W5) + b5    # 선형회귀 값 Z5\n",
        "\n",
        "y = A5 = tf.nn.softmax(Z5)\n",
        "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=T) )"
      ],
      "metadata": {
        "id": "ocfMM_TRlH88"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41foBIPAqKaO",
        "outputId": "245a13ee-6082-4059-fa2e-13048f044a15"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool_5:0' shape=(?, 4, 4, 128) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A4_flat\n",
        "#A4의 경우, 4*4*128 -> A4_flat의 경우, 2048이 되는데, 이를 통해 1차원이 된 flat이 된 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7JvzKkoqM0J",
        "outputId": "b26e50be-2c1f-40e1-b5f7-edc6aa10ddd1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape_5:0' shape=(?, 2048) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA65OoM1lKIF",
        "outputId": "e6fcc7f1-99a9-4047-9a80-92e8ba86534c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable_18:0' shape=(2048, 10) dtype=float32_ref>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y\n",
        "#y의 경우 10이 되는 이유는 0~9로 softmax가 된 값이 출력되기 때문."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlzKc6APqcBK",
        "outputId": "493e2730-77a0-4a83-d6b6-17776b2c2fd1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Softmax_3:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDmqiCBnqm0V",
        "outputId": "cd13e194-a623-4bca-8396-eaf8cd91f246"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_9:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab2hx5TWqrP2",
        "outputId": "dea8abe3-00a0-4a0a-cdcb-aeb695c8ffe5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean_7:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "train = optimizer.minimize(loss)  \n",
        "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
        "predicted_val = tf.equal( tf.argmax(A5, 1), tf.argmax(T, 1) )\n",
        "\n",
        "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
        "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))"
      ],
      "metadata": {
        "id": "pTcfYfDiqGlW"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"optimizer\", optimizer,\"\\n\")\n",
        "predicted_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltg_7zILqu-v",
        "outputId": "61b2047c-c2c4-4749-8783-fb73cc58de37"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizer <tensorflow.python.training.adam.AdamOptimizer object at 0x7fd619eb2a50> \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Equal_4:0' shape=(?,) dtype=bool>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tf.argmax(A5,1)\",tf.argmax(A5, 1),\"\\n\")\n",
        "print(\"tf.argmax(T,1)\",tf.argmax(T, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4R79L5XrYKf",
        "outputId": "a8ccb43f-3f56-4431-d0fd-5c828e66b6af"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.argmax(A5,1) Tensor(\"ArgMax_16:0\", shape=(?,), dtype=int64) \n",
            "\n",
            "tf.argmax(T,1) Tensor(\"ArgMax_17:0\", shape=(?,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.cast(predicted_val, dtype=tf.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evbRZUZfrkZv",
        "outputId": "cf2f2639-a4a7-465a-b5aa-70f0e59ef0c4"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Cast_7:0' shape=(?,) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with  tf.Session()  as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
        "    \n",
        "    start_time = datetime.now()#학습경과 시간\n",
        "    \n",
        "    for i in range(epochs):    # 30 번 반복수행\n",
        "        \n",
        "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
        "\n",
        "        for step in range(total_batch):\n",
        "            \n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
        "      \n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
        "        \n",
        "            if step % 100 == 0:\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
        "    end_time = datetime.now() \n",
        "    \n",
        "    print(\"\\nelapsed time = \", end_time - start_time) \n",
        "    \n",
        "    # Accuracy 확인\n",
        "    test_x_data = mnist.test.images    # 10000 X 784\n",
        "    test_t_data = mnist.test.labels    # 10000 X 10\n",
        "    \n",
        "    accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
        "    \n",
        "    print(\"\\nAccuracy = \", accuracy_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy1pZKZXi-_r",
        "outputId": "f058ffce-d591-43e0-cd59-8204089f597c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs =  0 , step =  0 , loss_val =  2.7656915\n",
            "epochs =  0 , step =  100 , loss_val =  2.2911062\n",
            "epochs =  0 , step =  200 , loss_val =  0.32244477\n",
            "epochs =  0 , step =  300 , loss_val =  0.29068494\n",
            "epochs =  0 , step =  400 , loss_val =  0.49716103\n",
            "epochs =  0 , step =  500 , loss_val =  0.22872306\n",
            "epochs =  1 , step =  0 , loss_val =  0.17914087\n",
            "epochs =  1 , step =  100 , loss_val =  0.048879962\n",
            "epochs =  1 , step =  200 , loss_val =  0.110925026\n",
            "epochs =  1 , step =  300 , loss_val =  0.12997532\n",
            "epochs =  1 , step =  400 , loss_val =  0.07831758\n",
            "epochs =  1 , step =  500 , loss_val =  0.0711055\n",
            "epochs =  2 , step =  0 , loss_val =  0.09930856\n",
            "epochs =  2 , step =  100 , loss_val =  0.029170342\n",
            "epochs =  2 , step =  200 , loss_val =  0.0364971\n",
            "epochs =  2 , step =  300 , loss_val =  0.056734797\n",
            "epochs =  2 , step =  400 , loss_val =  0.025782797\n",
            "epochs =  2 , step =  500 , loss_val =  0.026704539\n",
            "epochs =  3 , step =  0 , loss_val =  0.007075724\n",
            "epochs =  3 , step =  100 , loss_val =  0.08739378\n",
            "epochs =  3 , step =  200 , loss_val =  0.041551236\n",
            "epochs =  3 , step =  300 , loss_val =  0.0031939582\n",
            "epochs =  3 , step =  400 , loss_val =  0.015538687\n",
            "epochs =  3 , step =  500 , loss_val =  0.084546305\n",
            "epochs =  4 , step =  0 , loss_val =  0.0681466\n",
            "epochs =  4 , step =  100 , loss_val =  0.056600586\n",
            "epochs =  4 , step =  200 , loss_val =  0.030808361\n",
            "epochs =  4 , step =  300 , loss_val =  0.04678102\n",
            "epochs =  4 , step =  400 , loss_val =  0.0044408487\n",
            "epochs =  4 , step =  500 , loss_val =  0.0797349\n",
            "epochs =  5 , step =  0 , loss_val =  0.06591164\n",
            "epochs =  5 , step =  100 , loss_val =  0.021681506\n",
            "epochs =  5 , step =  200 , loss_val =  0.01666095\n",
            "epochs =  5 , step =  300 , loss_val =  0.02442686\n",
            "epochs =  5 , step =  400 , loss_val =  0.011871576\n",
            "epochs =  5 , step =  500 , loss_val =  0.022435214\n",
            "epochs =  6 , step =  0 , loss_val =  0.005745038\n",
            "epochs =  6 , step =  100 , loss_val =  0.030683035\n",
            "epochs =  6 , step =  200 , loss_val =  0.015476976\n",
            "epochs =  6 , step =  300 , loss_val =  0.0040003117\n",
            "epochs =  6 , step =  400 , loss_val =  0.010309308\n",
            "epochs =  6 , step =  500 , loss_val =  0.015496594\n",
            "epochs =  7 , step =  0 , loss_val =  0.0013816947\n",
            "epochs =  7 , step =  100 , loss_val =  0.0025612\n",
            "epochs =  7 , step =  200 , loss_val =  0.016002197\n",
            "epochs =  7 , step =  300 , loss_val =  0.004742035\n",
            "epochs =  7 , step =  400 , loss_val =  0.014075973\n",
            "epochs =  7 , step =  500 , loss_val =  0.0004320457\n",
            "epochs =  8 , step =  0 , loss_val =  0.0035696381\n",
            "epochs =  8 , step =  100 , loss_val =  0.09210069\n",
            "epochs =  8 , step =  200 , loss_val =  0.023028338\n",
            "epochs =  8 , step =  300 , loss_val =  0.11451625\n",
            "epochs =  8 , step =  400 , loss_val =  0.039396867\n",
            "epochs =  8 , step =  500 , loss_val =  0.00034164535\n",
            "epochs =  9 , step =  0 , loss_val =  0.03455189\n",
            "epochs =  9 , step =  100 , loss_val =  0.0024413054\n",
            "epochs =  9 , step =  200 , loss_val =  0.016874041\n",
            "epochs =  9 , step =  300 , loss_val =  0.06705267\n",
            "epochs =  9 , step =  400 , loss_val =  0.003176537\n",
            "epochs =  9 , step =  500 , loss_val =  0.008609741\n",
            "epochs =  10 , step =  0 , loss_val =  0.0023342352\n",
            "epochs =  10 , step =  100 , loss_val =  0.024281282\n",
            "epochs =  10 , step =  200 , loss_val =  0.0011551094\n",
            "epochs =  10 , step =  300 , loss_val =  0.01656939\n",
            "epochs =  10 , step =  400 , loss_val =  0.002275225\n",
            "epochs =  10 , step =  500 , loss_val =  0.0013579428\n",
            "epochs =  11 , step =  0 , loss_val =  0.010063877\n",
            "epochs =  11 , step =  100 , loss_val =  0.01015212\n",
            "epochs =  11 , step =  200 , loss_val =  0.018291714\n",
            "epochs =  11 , step =  300 , loss_val =  0.008877976\n",
            "epochs =  11 , step =  400 , loss_val =  0.015786432\n",
            "epochs =  11 , step =  500 , loss_val =  0.0023571874\n",
            "epochs =  12 , step =  0 , loss_val =  0.0072223037\n",
            "epochs =  12 , step =  100 , loss_val =  0.015213537\n",
            "epochs =  12 , step =  200 , loss_val =  0.0095176315\n",
            "epochs =  12 , step =  300 , loss_val =  0.0007212832\n",
            "epochs =  12 , step =  400 , loss_val =  0.01891737\n",
            "epochs =  12 , step =  500 , loss_val =  0.010643303\n",
            "epochs =  13 , step =  0 , loss_val =  0.0016723142\n",
            "epochs =  13 , step =  100 , loss_val =  0.0039263777\n",
            "epochs =  13 , step =  200 , loss_val =  0.0002467535\n",
            "epochs =  13 , step =  300 , loss_val =  0.00093920185\n",
            "epochs =  13 , step =  400 , loss_val =  0.0012448477\n",
            "epochs =  13 , step =  500 , loss_val =  0.014714111\n",
            "epochs =  14 , step =  0 , loss_val =  0.008860577\n",
            "epochs =  14 , step =  100 , loss_val =  0.014177846\n",
            "epochs =  14 , step =  200 , loss_val =  0.028829344\n",
            "epochs =  14 , step =  300 , loss_val =  0.00327423\n",
            "epochs =  14 , step =  400 , loss_val =  0.0030606387\n",
            "epochs =  14 , step =  500 , loss_val =  0.008959875\n",
            "epochs =  15 , step =  0 , loss_val =  0.0117924865\n",
            "epochs =  15 , step =  100 , loss_val =  0.00038594328\n",
            "epochs =  15 , step =  200 , loss_val =  0.0011307294\n",
            "epochs =  15 , step =  300 , loss_val =  0.0032160154\n",
            "epochs =  15 , step =  400 , loss_val =  0.00012390422\n",
            "epochs =  15 , step =  500 , loss_val =  0.003225814\n",
            "epochs =  16 , step =  0 , loss_val =  0.0034847322\n",
            "epochs =  16 , step =  100 , loss_val =  0.013702648\n",
            "epochs =  16 , step =  200 , loss_val =  0.0004936515\n",
            "epochs =  16 , step =  300 , loss_val =  0.00029094773\n",
            "epochs =  16 , step =  400 , loss_val =  0.00087450474\n",
            "epochs =  16 , step =  500 , loss_val =  0.00018716908\n",
            "epochs =  17 , step =  0 , loss_val =  0.00032587978\n",
            "epochs =  17 , step =  100 , loss_val =  0.00083720835\n",
            "epochs =  17 , step =  200 , loss_val =  0.08104889\n",
            "epochs =  17 , step =  300 , loss_val =  0.0021942803\n",
            "epochs =  17 , step =  400 , loss_val =  0.00024191239\n",
            "epochs =  17 , step =  500 , loss_val =  0.00023837881\n",
            "epochs =  18 , step =  0 , loss_val =  0.0018730536\n",
            "epochs =  18 , step =  100 , loss_val =  0.0026733617\n",
            "epochs =  18 , step =  200 , loss_val =  0.030954598\n",
            "epochs =  18 , step =  300 , loss_val =  0.009451531\n",
            "epochs =  18 , step =  400 , loss_val =  0.00035599005\n",
            "epochs =  18 , step =  500 , loss_val =  0.015593563\n",
            "epochs =  19 , step =  0 , loss_val =  0.00012227337\n",
            "epochs =  19 , step =  100 , loss_val =  0.0048167813\n",
            "epochs =  19 , step =  200 , loss_val =  0.00031507175\n",
            "epochs =  19 , step =  300 , loss_val =  0.05312226\n",
            "epochs =  19 , step =  400 , loss_val =  0.00038814425\n",
            "epochs =  19 , step =  500 , loss_val =  0.0040920773\n",
            "epochs =  20 , step =  0 , loss_val =  0.000103072234\n",
            "epochs =  20 , step =  100 , loss_val =  0.0001071872\n",
            "epochs =  20 , step =  200 , loss_val =  0.0035396377\n",
            "epochs =  20 , step =  300 , loss_val =  0.00027107509\n",
            "epochs =  20 , step =  400 , loss_val =  0.0010189157\n",
            "epochs =  20 , step =  500 , loss_val =  1.9609458e-06\n",
            "epochs =  21 , step =  0 , loss_val =  0.00065332686\n",
            "epochs =  21 , step =  100 , loss_val =  0.0012767335\n",
            "epochs =  21 , step =  200 , loss_val =  0.005261129\n",
            "epochs =  21 , step =  300 , loss_val =  0.016840374\n",
            "epochs =  21 , step =  400 , loss_val =  8.324117e-05\n",
            "epochs =  21 , step =  500 , loss_val =  0.008189256\n",
            "epochs =  22 , step =  0 , loss_val =  0.0014934603\n",
            "epochs =  22 , step =  100 , loss_val =  0.00019404937\n",
            "epochs =  22 , step =  200 , loss_val =  0.04720248\n",
            "epochs =  22 , step =  300 , loss_val =  0.0012116262\n",
            "epochs =  22 , step =  400 , loss_val =  4.3733682e-05\n",
            "epochs =  22 , step =  500 , loss_val =  0.004793396\n",
            "epochs =  23 , step =  0 , loss_val =  0.00035868888\n",
            "epochs =  23 , step =  100 , loss_val =  0.0031931766\n",
            "epochs =  23 , step =  200 , loss_val =  0.00088290125\n",
            "epochs =  23 , step =  300 , loss_val =  0.014666722\n",
            "epochs =  23 , step =  400 , loss_val =  0.00059910776\n",
            "epochs =  23 , step =  500 , loss_val =  0.00012504276\n",
            "epochs =  24 , step =  0 , loss_val =  0.012437005\n",
            "epochs =  24 , step =  100 , loss_val =  0.00038142106\n",
            "epochs =  24 , step =  200 , loss_val =  6.731384e-06\n",
            "epochs =  24 , step =  300 , loss_val =  9.849484e-05\n",
            "epochs =  24 , step =  400 , loss_val =  9.910317e-05\n",
            "epochs =  24 , step =  500 , loss_val =  0.0012940625\n",
            "epochs =  25 , step =  0 , loss_val =  0.00018803771\n",
            "epochs =  25 , step =  100 , loss_val =  0.00017606573\n",
            "epochs =  25 , step =  200 , loss_val =  0.00018698444\n",
            "epochs =  25 , step =  300 , loss_val =  1.3806383e-05\n",
            "epochs =  25 , step =  400 , loss_val =  2.645128e-06\n",
            "epochs =  25 , step =  500 , loss_val =  3.605533e-06\n",
            "epochs =  26 , step =  0 , loss_val =  0.00010067377\n",
            "epochs =  26 , step =  100 , loss_val =  9.691529e-06\n",
            "epochs =  26 , step =  200 , loss_val =  5.7639045e-05\n",
            "epochs =  26 , step =  300 , loss_val =  0.00014735328\n",
            "epochs =  26 , step =  400 , loss_val =  0.014300128\n",
            "epochs =  26 , step =  500 , loss_val =  3.3483822e-05\n",
            "epochs =  27 , step =  0 , loss_val =  0.21721886\n",
            "epochs =  27 , step =  100 , loss_val =  0.0015906239\n",
            "epochs =  27 , step =  200 , loss_val =  0.026195107\n",
            "epochs =  27 , step =  300 , loss_val =  0.0016137812\n",
            "epochs =  27 , step =  400 , loss_val =  9.223031e-05\n",
            "epochs =  27 , step =  500 , loss_val =  0.0015814654\n",
            "epochs =  28 , step =  0 , loss_val =  0.0025508592\n",
            "epochs =  28 , step =  100 , loss_val =  8.795647e-05\n",
            "epochs =  28 , step =  200 , loss_val =  6.759268e-06\n",
            "epochs =  28 , step =  300 , loss_val =  0.002493599\n",
            "epochs =  28 , step =  400 , loss_val =  2.111176e-05\n",
            "epochs =  28 , step =  500 , loss_val =  0.00018977548\n",
            "epochs =  29 , step =  0 , loss_val =  1.4960248e-06\n",
            "epochs =  29 , step =  100 , loss_val =  0.00043539185\n",
            "epochs =  29 , step =  200 , loss_val =  0.002998351\n",
            "epochs =  29 , step =  300 , loss_val =  6.057581e-05\n",
            "epochs =  29 , step =  400 , loss_val =  0.0032992044\n",
            "epochs =  29 , step =  500 , loss_val =  0.000200418\n",
            "\n",
            "elapsed time =  0:01:08.994188\n",
            "\n",
            "Accuracy =  0.9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('step=500, loss_val')\n",
        "plt.xlabel('epoch')\n",
        "x=[0, 1, 2, 3, 4, 5, 6, 7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n",
        "y=[0.22872306, 0.0711055, 0.026704539, 0.084546305, 0.0797349, 0.022435214, 0.015496594, 0.0004320457, 0.00034164535, 0.008609741, 0.0013579428, 0.0023571874, 0.010643303, 0.014714111, 0.008959875, 0.003225814, 0.00018716908, 0.00023837881, 0.015593563, 0.0040920773, 1.9609458e-06, 0.008189256, 0.004793396, 0.00012504276, 0.0012940625, 3.605533e-06, 3.3483822e-05, 0.0015814654, 0.00018977548, 0.000200418]\n",
        "plt.plot(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "ZmAMATHVzq8G",
        "outputId": "9f69708b-df38-4692-e57d-3e635d5f87f4"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd617716a10>]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
